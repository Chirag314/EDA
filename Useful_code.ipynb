{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Useful code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPu0QiMLSNjIMH0/N0LvuiF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chirag314/EDA/blob/main/Useful_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pandas basics\n",
        "Delete rows with NAN values\n",
        ">1.axis: Default – 0\n",
        "0, or ‘index’ : Drop rows which contain NaN values.\n",
        "1, or ‘columns’ : Drop columns which contain NaN value.\n",
        ">2.how: Default – ‘any’\n",
        "‘any’ : Drop rows / columns which contain any NaN values.\n",
        "‘all’ : Drop rows / columns which contain all NaN values.\n",
        ">3.thresh (int): Optional\n",
        "Delete rows/columns which contains less than minimun thresh number of non-NaN values.\n",
        ">4.inplace (bool): Default- False\n",
        "If True, modifies the calling dataframe object\n",
        "\n",
        "\n",
        "Returns\n",
        "\n",
        "If inplace==True, the return None, else returns a new dataframe by deleting the rows/columns based on NaN values\n",
        "you must add inplace = True argument, if you want the dataframe to be actually updated."
      ],
      "metadata": {
        "id": "QP5HaKbEI5BI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVJAF2xZIvHK"
      },
      "outputs": [],
      "source": [
        "#Pandas delete rows with NAN values\n",
        "DataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows which contain all NaN values\n",
        "df = df.dropna(axis=0, how='all')\n",
        "df.dropna(axis=1)# Drop columns that contain any NaN value.\n",
        "df.dropna(thresh=3,axis=1)# Drop any column that have less than 3 NaN values\n",
        "df.dropna(axis=column,how='all')# Dron columns that contain ALL NaN values."
      ],
      "metadata": {
        "id": "eEu26wPHK4fB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#If you want to select rows with at least one NaN value, then you could use isna + any on axis=1:\n",
        "\n",
        "df[df.isna().any(axis=1)]\n",
        "#If you want to select rows with a certain number of NaN values, then you could use isna + sum on axis=1 + gt. For example, the following will fetch rows with at least 2 NaN values:\n",
        "\n",
        "df[df.isna().sum(axis=1)>1]\n",
        "\n",
        "# Select not NaN values\n",
        "df[df.notna().all(axis=1)]"
      ],
      "metadata": {
        "id": "lpwrXpCTM400"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print all columns names\n",
        "print(df.columns)\n",
        "#Print all columns tyoes\n",
        "print(df.dtypes)\n",
        "# Select specific data types \n",
        "only_ints = df.select_dtypes(include=['int'])\n",
        "print(only_ints.columns)"
      ],
      "metadata": {
        "id": "1HLUQyzP768W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For a dataframe df, one can use any of the following: Number of rows in dataframe\n",
        "df.shape\n",
        "len(df.index)\n",
        "len(df.comlumns)# To find out number of columns\n",
        "df.shape[0]\n",
        "df[df.columns[0]].count() (== number of non-NaN values in first column)\n",
        "count_row = df.shape[0]  # Gives number of rows\n",
        "count_col = df.shape[1]  # Gives number of columns\n",
        "r, c = df.shape"
      ],
      "metadata": {
        "id": "s8OBL57nReev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete rows with a condition.\n",
        "#Delete all rows if a row contains 3 missing values\n",
        "df.drop(df[df.isna().sum(axis=1)==3].index,inplace=True)\n",
        "\n",
        "#To remove all rows where column 'score' is < 50 and > 20\n",
        "#The operators are: | for or, & for and, and ~ for not. These must be grouped by using parentheses.\n",
        "df = df.drop(df[(df.score < 50) & (df.score > 20)].index)\n",
        "\n",
        "# Drop record with specified values. Drop record where area >4000 and price , 210000\n",
        "df_train = df_train.drop(df_train[(df_train['GrLivArea']>4000) & (df_train['SalePrice']<210000)].index)"
      ],
      "metadata": {
        "id": "r455qNCgaQT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change pandas display option in editor\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "# To display all columns in wide format so that they dont print in different pages if more columns.\n",
        "# Default option is True--> set it False to display all columns in wide format.\n",
        "pd.set_option('display.expand_frame_repr', False)"
      ],
      "metadata": {
        "id": "ArSAT1x3d3Gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert NN output probability to boolean values.\n",
        "test2.loc[test2['Trans'] < 0.5, 'Transported'] = 'False' \n",
        "test2.loc[test2['Trans'] >= 0.5, 'Transported'] = 'True' \n",
        "test2.drop('Trans',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "B925e_ZhNz63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To find out unique values within columns\n",
        "x.iloc[:,3].unique() # All unique values in column 3\n",
        "temp.Pclass.unique()"
      ],
      "metadata": {
        "id": "_DxN-opXrWdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert numeric values to float\n",
        "numeric_list = df.select_dtypes(include=[np.number]).columns\n",
        "df[numeric_list] = df[numeric_list].astype(np.float32)"
      ],
      "metadata": {
        "id": "SmxA_Q4j7jqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set floating point option to display 4 decimals.\n",
        "\n",
        "pd.set_option('display.float_format', lambda x: '%.4f' % x)"
      ],
      "metadata": {
        "id": "bnGqncNjtTtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many data is type of object\n",
        "\n",
        "df_data.select_dtypes(['object']).head()"
      ],
      "metadata": {
        "id": "dXICP9Ys3UQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the frequency of dataframe columns\n",
        "\n",
        "df1 = df['Courses'].value_counts()\n",
        "df1 = df.Courses.value_counts\n",
        "df1 = df.groupby('Courses').count()\n",
        "df1 = df.index.value_counts()"
      ],
      "metadata": {
        "id": "LF1rrZC4OCZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform all object and boolean column to integer\n",
        "for colname in x_train.select_dtypes(['object','bool']).columns:\n",
        "  x_train[colname]=LabelEncoder().fit_transform(x_train[colname])\n"
      ],
      "metadata": {
        "id": "Ar2vqdqa0_yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop whole column\n",
        "train=train.drop(['Age'].index,inplace=True)"
      ],
      "metadata": {
        "id": "4J-e26q5q5al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LEts check correlation matric to find out which features are important in prediction survival\n",
        "\n",
        "corrMatrix = train.corr()\n",
        "sns.heatmap(corrMatrix, annot=True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kFFbttYxvg0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross tab frequency table\n",
        "train.groupby(['Fare', 'Survived'])['Fare'].count().unstack()"
      ],
      "metadata": {
        "id": "kbkpZjDhyC45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use of min max scaler in data which is not normal and has a range of values such as pixel values\n",
        "# Use of standard scaler when data is normally distributed.\n",
        "from sklearn.preprocessing import MinMaxScale\n",
        "scaler=MinMaxScaler()\n",
        "train['Fare']=scaler.fit_transform(train[['Fare']])"
      ],
      "metadata": {
        "id": "W7p2mPlb4Tto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Another way to find median\n",
        "median = df['Age'].describe()[5]\n"
      ],
      "metadata": {
        "id": "FJBM-lcRDarA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute missing values with mode for fare in test data\n",
        "\n",
        "mode=train['Embarked'].value_counts().index[0]\n",
        "train['Embarked']=train['Embarked'].fillna(mode)\n",
        "train.isnull().sum()"
      ],
      "metadata": {
        "id": "J0IPuN0H6nrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Draw barplot with cross tab freq values.\n",
        "ax=sns.countplot(data=temp,x='Pclass',hue='Survived')\n",
        "ax.bar_label(ax.containers[0])\n",
        "ax.bar_label(ax.containers[1])\n",
        "plt.legend(title='Survived or not',loc='upper left',labels=['No','Yes'])"
      ],
      "metadata": {
        "id": "Smai-73RpsDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to categories categories\n",
        "  data['Age']=pd.cut(data['Age'],bins=[0,12,20,40,120], labels=['Children','Teenage','Adult','Elder'])"
      ],
      "metadata": {
        "id": "TorY3W_9yqAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation metrics from history object\n",
        "\n",
        "train_loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "train_accuracy=history.history['accuracy']\n",
        "val_accuracy=history.history['val_accuracy']\n",
        "epochs=range(len(train_accuracy))\n",
        "#plot loss\n",
        "plt.plot(epochs,train_loss,color='b',label='Train loss')\n",
        "plt.plot(epochs,val_loss,color='r',label='Validation loss')\n",
        "#plot accuracy\n",
        "plt.plot(epochs,train_accuracy,color='b',label='Train accuracy')\n",
        "plt.plot(epochs,val_accuracy,color='r',label='Validation accuracy')"
      ],
      "metadata": {
        "id": "gRlNb_aN-3PW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#XGB model \n",
        "xgb_model=xgb.XGBClassifier(objective='binary:logistic',random_state=42)\n",
        "\n",
        "xgb_model.fit(tr_x,tr_y)\n",
        "y_pred=xgb_model.predict(cv_x)\n",
        "print(confusion_matrix(cv_y,y_pred))"
      ],
      "metadata": {
        "id": "L0qS_ZY6U1Or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Train the model: xg_reg\n",
        "xg_reg = xgb.train(params=params, dtrain=housing_dmatrix, num_boost_round=10)\n",
        "\n",
        "# Plot the feature importances \n",
        "xgb.plot_importance(xg_reg)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4R04_ZjJqQTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#list comprehension Square all values in list x\n",
        "#num**2 for num in x\n",
        "\n",
        "# lambda function to square all values \n",
        "list(map(lambda x: x**2,range(1,6)))\n",
        "\n",
        "#argmax() and argmin() are used to find index location of max and min values in numpy array."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-hjNTPlnLDC",
        "outputId": "6ef411cb-bd40-4510-bade-42f6e6cc6b7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 4, 9, 16, 25]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "arr=np.arange(0,5)\n",
        "arr\n",
        "arr/arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgNIAKCx0BzG",
        "outputId": "76a22084-1c38-472b-d197-c6ea99e0e5a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([nan,  1.,  1.,  1.,  1.])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting index with col_name\n",
        "df.set_index('col_name',inplace=True)\n",
        "\n",
        "# Reseting index of the dataframe to numerical index(which is default index)\n",
        "\n",
        "df.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "bngYLJTwhBoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputing missing values with LOCF or Next values\n",
        "data_dict={'A':[1,2 ,np.nan,4,np.nan],\n",
        "           'B':[np.nan, np.nan,np.nan,np.nan,np.nan],\n",
        "           'C':[11,12,13,14,15],\n",
        "           'D':[16,np.nan,18,19,20]}\n",
        "df=pd.DataFrame(data_dict)\n",
        "df.fillna(method='ffill')# Use the last valid observation to fill the gap\n",
        "df.fillna(method='bfill')#Use next valid observation to fill the gap\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "h5SPtEiwkL1J",
        "outputId": "e9715d6f-8d4c-496f-bd52-ee961b6b1770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     A   B   C     D\n",
              "0  1.0 NaN  11  16.0\n",
              "1  2.0 NaN  12  18.0\n",
              "2  4.0 NaN  13  18.0\n",
              "3  4.0 NaN  14  19.0\n",
              "4  NaN NaN  15  20.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fe47fb07-ea4f-41ad-b565-c6e2bd2f1232\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe47fb07-ea4f-41ad-b565-c6e2bd2f1232')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fe47fb07-ea4f-41ad-b565-c6e2bd2f1232 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fe47fb07-ea4f-41ad-b565-c6e2bd2f1232');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# merge datasets joins\n",
        "pd.merge(df1,df2,how='inner',on=['key'])\n",
        "pd.merge(df1,df2,how='outer',on=['key'])\n",
        "pd.merge(df1,df2,how='left',on=['key'])\n",
        "pd.merge(df1,df2,how='right',on=['key'])\n",
        "\n",
        "#Stack datasets\n",
        "pd.concat([df1],[df2])"
      ],
      "metadata": {
        "id": "fEhroj9hnTxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Two features with highest chi-squared statistics are selected\n",
        "#For selecting categorical features .Change k for number of features.\n",
        "chi2_features = SelectKBest(chi2, k = 2)\n",
        "X_kbest_features = chi2_features.fit_transform(X, y)"
      ],
      "metadata": {
        "id": "Ro7o8yEKIMTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print importnant features in the model\n",
        "\n",
        "model=ExtraTreesClassifier()\n",
        "model.fit(x,y)\n",
        "print(model.feature_importances_)\n",
        "feature_importances=pd.Series(model.feature_importanes_,index=x.columns)\n",
        "feature_importances.nlargest(10).plot(kind='barh')# Draw horizontal bar graph of 10 most important features.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8SshKKVcYkwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The correlation matrix shows only linear dependence. If we plot a rolling mean of the target probability for every feature, we'll see nonlinear dependences as well:\n",
        "# If we get non linear dependencies then \n",
        "ax.scatter(temp[f], temp.state.rolling(15000, center=True).mean(), s=2)# Plot rolling mean of 15000 values against feature ."
      ],
      "metadata": {
        "id": "ALF0SR2SwHSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use set_index and reset_index to find out how many family memebers from family name\n",
        "test_df['FamilyId'] = test_df['PassengerId'].str.split(\"_\", n=2, expand=True)[0]\n",
        "test_df['Family Name'] = test_df['Name'].str.split(' ', n=2, expand=True)[1]\n",
        "test_df = test_df.set_index(['FamilyId','Family Name'])# Setting the index with FamilyId and Family Name witll set index as an example below\n",
        "test_df['Family Size'] = 1 # Default family size\n",
        "​\n",
        "for i in range(test_df.shape[0]):\n",
        "    fam_size = test_df.loc[test_df.index[i],:].shape[0]# this gives list of (number of family members, total columns in test datasets)--> shape[0] will give total familly members\n",
        "    test_df.loc[test_df.index[i],'Family Size'] = fam_size\n",
        "​\n",
        "test_df=test_df.reset_index()# Reset index to default"
      ],
      "metadata": {
        "id": "Vu94XFwAa1Qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering dataset\n",
        "#Check if countries are in column \n",
        "\n",
        "countries=[\"United States\",\"India\",\"United Kingdon\",\"Germany\",\"Canada\"]\n",
        "filt=df['Country'].isin(countries)\n",
        "df.loc[filt,'Country']"
      ],
      "metadata": {
        "id": "fnVAG42d1e6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find sum across columns \n",
        "df[['a','b','d']].agg('sum', axis=1)\n",
        "The advantage of agg is that you can use multiple aggregation functions:\n",
        "\n",
        "df[['a','b','d']].agg(['sum', 'prod', 'min', 'max'], axis=1)"
      ],
      "metadata": {
        "id": "fnzCqO_yD3RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filtering based on if else condition. Create/update column based on existing column conditions.\n",
        "df['Interest']=[i*0.02 if i<20 else i*0.04 for i in df.debts]"
      ],
      "metadata": {
        "id": "RhsrOuyQRW4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To achieve a compact visualization of the distribution that retains histogram-like characteristics, Hintze and Nelson (1998) developed the violin plot (c).\n",
        "#Violin plot is created by generating a density or distribution of the data and its mirror image. In the above figure we can see the violin plot, where we can\n",
        " #now see the many distinct peaks in citric acid distribution. The lower quartile, median, and upper quartile can be added to a violin plot to also consider \n",
        "# this information in the overall assessment of the distribution.\n",
        " fig = go.Figure(px.violin(df, y = 'sulphates', title = 'Violin Plot of Sulphates', box = True))\n",
        "fig.update_layout(title_x=0.5)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "R_ffVaO0sZqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#When performing Label Encoding below, you must encode train and test together as in\n",
        "df = pd.concat([train[col],test[col]],axis=0)\n",
        "# PERFORM FEATURE ENGINEERING HERE\n",
        "train[col] = df[:len(train)]\n",
        "test[col] = df[len(train):]"
      ],
      "metadata": {
        "id": "-GoBSeTf9BcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Frequency Encoding\n",
        "#Frequency encoding is a powerful technique that allows LGBM to see whether column values are rare or common. For example, if you want LGBM to \"see\" which credit cards are used infrequently, try\n",
        "\n",
        "temp = df['card1'].value_counts().to_dict()\n",
        "df['card1_counts'] = df['card1'].map(temp)"
      ],
      "metadata": {
        "id": "oeu9UxfC-YAQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}